## A Contrastive Learning Approach to Bug Severity Classification with Large Language Model Embeddings
Bug severity classification is critical for prioritizing software issues effectively. This study leverages Large Language Models (LLMs) such as CodeBERT to classify bug reports based on severity levels, providing contextual embeddings of bug descriptions. A Contrastive Learning approach is employed to enhance the embedding space, aligning similar bug reports while separating dissimilar ones, thus improving classification accuracy. The proposed approach is evaluated on the NASA Pits and Mozilla datasets and compared against baseline models using traditional embedding models like Doc2Vec. Results show that fine-tuning LLMs with contrastive learning significantly improves performance, particularly on imbalanced and diverse datasets, achieving higher accuracy and F1-Scores. Additionally, the study demonstrates that LLMs excel in handling longer bug descriptions, while Doc2Vec remains suitable for smaller, structured datasets.
