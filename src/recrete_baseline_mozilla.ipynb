{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##mozilla"
      ],
      "metadata": {
        "id": "SRzAh2OQCvtv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-d4vxH1euxv",
        "outputId": "a88652b2-f95d-4c59-f5c6-b6fb23c909ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 10 21:38:06 2024\n",
            "Preprocessing training data...\n",
            "Number of valid training documents: 7825\n",
            "Preprocessing test data...\n",
            "Number of valid test documents: 1957\n",
            "Building vocabulary...\n",
            "Vocabulary size (DM): 27470\n",
            "Vocabulary size (DBOW): 27469\n",
            "Training models...\n",
            "Generating training data...\n",
            "Generating testing data...\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.7379\n",
            "Precision | Recall | F-Score\n",
            "(0.7195068326466643, 0.7378640776699029, 0.7278383787618734, None)\n",
            "Tue Dec 10 21:42:54 2024\n",
            "TOTAL RUNTIME:  287.48146080970764 s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pprint import pprint\n",
        "import gensim\n",
        "import multiprocessing\n",
        "\n",
        "# Helper functions for data loading and preprocessing\n",
        "def load_data(dataset, train=True, percent=0.8):\n",
        "    '''Reads in and formats data from the dataset with train/test split.'''\n",
        "    df = pd.read_csv(dataset.path, sep=',', encoding='ISO-8859-1')\n",
        "    df = df.dropna(subset=[\"Severity\", \"Description\"])  # Drop rows with missing Severity or Description\n",
        "    df['Severity'] = df['Severity'].astype(int)  # Convert Severity to int\n",
        "    df['Description'] = df['Description'].astype(str).str.strip()  # Ensure Description is a string\n",
        "\n",
        "    # Filter out invalid rows\n",
        "    df = df[df['Description'] != '']\n",
        "\n",
        "    raw_data = df[['Description', 'Severity']].to_numpy()  # Use only Description and Severity columns\n",
        "\n",
        "    # Split the dataset into train and test based on the percent\n",
        "    train_data, test_data = train_test_split(raw_data, test_size=(1 - percent), random_state=42)\n",
        "    return train_data if train else test_data\n",
        "\n",
        "def preprocess(train_data, test_data):\n",
        "    '''Generate paragraph vectors using Doc2Vec.'''\n",
        "    print(\"Preprocessing training data...\")\n",
        "    train_corpus = list(_read_corpus(train_data))\n",
        "    print(f\"Number of valid training documents: {len(train_corpus)}\")\n",
        "\n",
        "    print(\"Preprocessing test data...\")\n",
        "    test_corpus = list(_read_corpus(test_data, tokens_only=True))\n",
        "    print(f\"Number of valid test documents: {len(test_corpus)}\")\n",
        "\n",
        "    if len(train_corpus) == 0 or len(test_corpus) == 0:\n",
        "        raise ValueError(\"No valid data found after preprocessing. Check the 'Description' column.\")\n",
        "\n",
        "    cores = max(1, multiprocessing.cpu_count() // 2)  # Use half the cores\n",
        "\n",
        "    # Initialize Doc2Vec models\n",
        "    model_DM = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=1, dm_concat=1)\n",
        "    model_DBOW = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=0)\n",
        "\n",
        "    # Build vocabulary\n",
        "    print(\"Building vocabulary...\")\n",
        "    model_DM.build_vocab(train_corpus)\n",
        "    model_DBOW.build_vocab(train_corpus)\n",
        "\n",
        "    print(f\"Vocabulary size (DM): {len(model_DM.wv.key_to_index)}\")\n",
        "    print(f\"Vocabulary size (DBOW): {len(model_DBOW.wv.key_to_index)}\")\n",
        "\n",
        "    if len(model_DM.wv.key_to_index) == 0 or len(model_DBOW.wv.key_to_index) == 0:\n",
        "        raise ValueError(\"Vocabulary is empty. Check your input data or preprocessing.\")\n",
        "\n",
        "    # Train Doc2Vec models\n",
        "    print(\"Training models...\")\n",
        "    model_DM.train(train_corpus, total_examples=model_DM.corpus_count, epochs=model_DM.epochs)\n",
        "    model_DBOW.train(train_corpus, total_examples=model_DBOW.corpus_count, epochs=model_DBOW.epochs)\n",
        "\n",
        "    # Generate training data\n",
        "    print(\"Generating training data...\")\n",
        "    X_train = [(list(model_DM.dv[i]) + list(model_DBOW.dv[i])) for i in range(len(train_corpus))]\n",
        "    Y_train = [doc[1] for doc in train_data]\n",
        "\n",
        "    print(\"Generating testing data...\")\n",
        "    X_test = [(list(model_DM.infer_vector(test_corpus[i])) + list(model_DBOW.infer_vector(test_corpus[i]))) for i in range(len(test_corpus))]\n",
        "    Y_test = [doc[1] for doc in test_data]\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def _read_corpus(data, tokens_only=False):\n",
        "    '''Helper function to prepare data for Doc2Vec.'''\n",
        "    for i, line in enumerate(data):\n",
        "        description = str(line[0]).strip()  # Ensure the description is a string and trimmed\n",
        "        if not description:\n",
        "            continue\n",
        "        tokens = gensim.utils.simple_preprocess(description)\n",
        "        if tokens_only:\n",
        "            yield tokens\n",
        "        else:\n",
        "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "# Classifier\n",
        "class ASP():\n",
        "    def __init__(self, X_train, Y_train, X_test, Y_test):\n",
        "        self.X_train, self.Y_train = X_train, Y_train\n",
        "        self.X_test, self.Y_test = X_test, Y_test\n",
        "        self.classifier = MLPClassifier(alpha=0.7, max_iter=10000)\n",
        "\n",
        "    def fit(self):\n",
        "        self.classifier.fit(self.X_train, self.Y_train)\n",
        "\n",
        "    def predict(self):\n",
        "        prediction = self.classifier.predict(self.X_test)\n",
        "        accuracy = accuracy_score(self.Y_test, prediction)\n",
        "        prf1 = precision_recall_fscore_support(y_true=self.Y_test, y_pred=prediction, average='weighted')\n",
        "\n",
        "        print('Evaluation Metrics:')\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print('Precision | Recall | F-Score')\n",
        "        pprint(prf1)\n",
        "\n",
        "# Dataset class\n",
        "class Dataset():\n",
        "    def __init__(self, path, project_id):\n",
        "        self.path = path\n",
        "        self.project_id = project_id\n",
        "\n",
        "# Experiment class\n",
        "class Experiment():\n",
        "    def __init__(self, train_data, test_data):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def run(self):\n",
        "        X_train, Y_train, X_test, Y_test = preprocess(self.train_data, self.test_data)\n",
        "        classifier = ASP(X_train, Y_train, X_test, Y_test)\n",
        "        classifier.fit()\n",
        "        classifier.predict()\n",
        "\n",
        "# Script to run experiment with 80/20 train-test split\n",
        "a = Dataset('/content/mozilla_bug_report_data.csv', project_id=1)  # Replace with your dataset path\n",
        "train_data = load_data(a, train=True, percent=0.8)\n",
        "test_data = load_data(a, train=False, percent=0.8)\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "start = time.time()\n",
        "\n",
        "experiment = Experiment(train_data, test_data)\n",
        "experiment.run()\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "print('TOTAL RUNTIME: ', time.time() - start, 's')\n",
        "print('')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pprint import pprint\n",
        "import gensim\n",
        "import multiprocessing\n",
        "\n",
        "# Helper functions for data loading and preprocessing\n",
        "def load_data(dataset, train=True, percent=0.8):\n",
        "    '''Reads in and formats data from the dataset with train/test split.'''\n",
        "    df = pd.read_csv(dataset.path, sep=',', encoding='ISO-8859-1')\n",
        "    df = df.dropna(subset=[\"Severity\", \"short_description\"])  # Drop rows with missing Severity or Description\n",
        "    df['Severity'] = df['Severity'].astype(int)  # Convert Severity to int\n",
        "    df['short_description'] = df['short_description'].astype(str).str.strip()  # Ensure Description is a string\n",
        "\n",
        "    # Filter out invalid rows\n",
        "    df = df[df['short_description'] != '']\n",
        "\n",
        "    raw_data = df[['short_description', 'Severity']].to_numpy()  # Use only Description and Severity columns\n",
        "\n",
        "    # Split the dataset into train and test based on the percent\n",
        "    train_data, test_data = train_test_split(raw_data, test_size=(1 - percent), random_state=42)\n",
        "    return train_data if train else test_data\n",
        "\n",
        "def preprocess(train_data, test_data):\n",
        "    '''Generate paragraph vectors using Doc2Vec.'''\n",
        "    print(\"Preprocessing training data...\")\n",
        "    train_corpus = list(_read_corpus(train_data))\n",
        "    print(f\"Number of valid training documents: {len(train_corpus)}\")\n",
        "\n",
        "    print(\"Preprocessing test data...\")\n",
        "    test_corpus = list(_read_corpus(test_data, tokens_only=True))\n",
        "    print(f\"Number of valid test documents: {len(test_corpus)}\")\n",
        "\n",
        "    if len(train_corpus) == 0 or len(test_corpus) == 0:\n",
        "        raise ValueError(\"No valid data found after preprocessing. Check the 'Description' column.\")\n",
        "\n",
        "    cores = max(1, multiprocessing.cpu_count() // 2)  # Use half the cores\n",
        "\n",
        "    # Initialize Doc2Vec models\n",
        "    model_DM = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=1, dm_concat=1)\n",
        "    model_DBOW = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=0)\n",
        "\n",
        "    # Build vocabulary\n",
        "    print(\"Building vocabulary...\")\n",
        "    model_DM.build_vocab(train_corpus)\n",
        "    model_DBOW.build_vocab(train_corpus)\n",
        "\n",
        "    print(f\"Vocabulary size (DM): {len(model_DM.wv.key_to_index)}\")\n",
        "    print(f\"Vocabulary size (DBOW): {len(model_DBOW.wv.key_to_index)}\")\n",
        "\n",
        "    if len(model_DM.wv.key_to_index) == 0 or len(model_DBOW.wv.key_to_index) == 0:\n",
        "        raise ValueError(\"Vocabulary is empty. Check your input data or preprocessing.\")\n",
        "\n",
        "    # Train Doc2Vec models\n",
        "    print(\"Training models...\")\n",
        "    model_DM.train(train_corpus, total_examples=model_DM.corpus_count, epochs=model_DM.epochs)\n",
        "    model_DBOW.train(train_corpus, total_examples=model_DBOW.corpus_count, epochs=model_DBOW.epochs)\n",
        "\n",
        "    # Generate training data\n",
        "    print(\"Generating training data...\")\n",
        "    X_train = [(list(model_DM.dv[i]) + list(model_DBOW.dv[i])) for i in range(len(train_corpus))]\n",
        "    Y_train = [doc[1] for doc in train_data]\n",
        "\n",
        "    print(\"Generating testing data...\")\n",
        "    X_test = [(list(model_DM.infer_vector(test_corpus[i])) + list(model_DBOW.infer_vector(test_corpus[i]))) for i in range(len(test_corpus))]\n",
        "    Y_test = [doc[1] for doc in test_data]\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def _read_corpus(data, tokens_only=False):\n",
        "    '''Helper function to prepare data for Doc2Vec.'''\n",
        "    for i, line in enumerate(data):\n",
        "        description = str(line[0]).strip()  # Ensure the description is a string and trimmed\n",
        "        if not description:\n",
        "            continue\n",
        "        tokens = gensim.utils.simple_preprocess(description)\n",
        "        if tokens_only:\n",
        "            yield tokens\n",
        "        else:\n",
        "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "# Classifier\n",
        "class ASP():\n",
        "    def __init__(self, X_train, Y_train, X_test, Y_test):\n",
        "        self.X_train, self.Y_train = X_train, Y_train\n",
        "        self.X_test, self.Y_test = X_test, Y_test\n",
        "        self.classifier = MLPClassifier(alpha=0.7, max_iter=10000)\n",
        "\n",
        "    def fit(self):\n",
        "        self.classifier.fit(self.X_train, self.Y_train)\n",
        "\n",
        "    def predict(self):\n",
        "        prediction = self.classifier.predict(self.X_test)\n",
        "        accuracy = accuracy_score(self.Y_test, prediction)\n",
        "        prf1 = precision_recall_fscore_support(y_true=self.Y_test, y_pred=prediction, average='weighted')\n",
        "\n",
        "        print('Evaluation Metrics:')\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print('Precision | Recall | F-Score')\n",
        "        pprint(prf1)\n",
        "\n",
        "# Dataset class\n",
        "class Dataset():\n",
        "    def __init__(self, path, project_id):\n",
        "        self.path = path\n",
        "        self.project_id = project_id\n",
        "\n",
        "# Experiment class\n",
        "class Experiment():\n",
        "    def __init__(self, train_data, test_data):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def run(self):\n",
        "        X_train, Y_train, X_test, Y_test = preprocess(self.train_data, self.test_data)\n",
        "        classifier = ASP(X_train, Y_train, X_test, Y_test)\n",
        "        classifier.fit()\n",
        "        classifier.predict()\n",
        "\n",
        "# Script to run experiment with 80/20 train-test split\n",
        "a = Dataset('/content/mozilla_bug_report_data.csv', project_id=1)  # Replace with your dataset path\n",
        "train_data = load_data(a, train=True, percent=0.8)\n",
        "test_data = load_data(a, train=False, percent=0.8)\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "start = time.time()\n",
        "\n",
        "experiment = Experiment(train_data, test_data)\n",
        "experiment.run()\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "print('TOTAL RUNTIME: ', time.time() - start, 's')\n",
        "print('')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKgBtllhXtRF",
        "outputId": "396d7650-6fc4-4699-e2db-4f09115b3e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 15 04:54:39 2024\n",
            "Preprocessing training data...\n",
            "Number of valid training documents: 7997\n",
            "Preprocessing test data...\n",
            "Number of valid test documents: 2000\n",
            "Building vocabulary...\n",
            "Vocabulary size (DM): 8948\n",
            "Vocabulary size (DBOW): 8947\n",
            "Training models...\n",
            "Generating training data...\n",
            "Generating testing data...\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.8235\n",
            "Precision | Recall | F-Score\n",
            "(0.7158100085230732, 0.8235, 0.7643457209738342, None)\n",
            "Sun Dec 15 04:56:22 2024\n",
            "TOTAL RUNTIME:  103.02941250801086 s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cross product"
      ],
      "metadata": {
        "id": "nFaFrf_yBVr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pprint import pprint\n",
        "import gensim\n",
        "import multiprocessing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Helper functions for data loading and preprocessing\n",
        "def load_data(dataset, train=True):\n",
        "    '''Reads in and formats data from the dataset based on product_name split.'''\n",
        "    df = pd.read_csv(dataset.path, sep=',', encoding='ISO-8859-1')\n",
        "    df = df.dropna(subset=[\"Severity\", \"Description\", \"product_name\"])  # Drop rows with missing columns\n",
        "    df['Severity'] = df['Severity'].astype(int)  # Convert Severity to int\n",
        "    df['Description'] = df['Description'].astype(str).str.strip()  # Ensure Description is a string\n",
        "\n",
        "    # Filter out invalid rows\n",
        "    df = df[df['Description'] != '']\n",
        "\n",
        "    # Split based on product_name\n",
        "    test_data = df[df['product_name'] == 'CORE'][['Description', 'Severity']].to_numpy()\n",
        "    train_data = df[df['product_name'] != 'CORE'][['Description', 'Severity']].to_numpy()\n",
        "\n",
        "    return train_data if train else test_data\n",
        "\n",
        "def preprocess(train_data, test_data):\n",
        "    '''Generate paragraph vectors using Doc2Vec.'''\n",
        "    print(\"Preprocessing training data...\")\n",
        "    train_corpus = list(_read_corpus(train_data))\n",
        "    print(f\"Number of valid training documents: {len(train_corpus)}\")\n",
        "\n",
        "    print(\"Preprocessing test data...\")\n",
        "    test_corpus = list(_read_corpus(test_data, tokens_only=True))\n",
        "    print(f\"Number of valid test documents: {len(test_corpus)}\")\n",
        "\n",
        "    if len(train_corpus) == 0 or len(test_corpus) == 0:\n",
        "        raise ValueError(\"No valid data found after preprocessing. Check the input data.\")\n",
        "\n",
        "    cores = max(1, multiprocessing.cpu_count() // 2)  # Use half the cores\n",
        "\n",
        "    # Initialize Doc2Vec models\n",
        "    model_DM = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=1, dm_concat=1)\n",
        "    model_DBOW = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=0)\n",
        "\n",
        "    # Build vocabulary\n",
        "    print(\"Building vocabulary...\")\n",
        "    model_DM.build_vocab(train_corpus)\n",
        "    model_DBOW.build_vocab(train_corpus)\n",
        "\n",
        "    print(f\"Vocabulary size (DM): {len(model_DM.wv.key_to_index)}\")\n",
        "    print(f\"Vocabulary size (DBOW): {len(model_DBOW.wv.key_to_index)}\")\n",
        "\n",
        "    if len(model_DM.wv.key_to_index) == 0 or len(model_DBOW.wv.key_to_index) == 0:\n",
        "        raise ValueError(\"Vocabulary is empty. Check your input data or preprocessing.\")\n",
        "\n",
        "    # Train Doc2Vec models\n",
        "    print(\"Training models...\")\n",
        "    model_DM.train(train_corpus, total_examples=model_DM.corpus_count, epochs=model_DM.epochs)\n",
        "    model_DBOW.train(train_corpus, total_examples=model_DBOW.corpus_count, epochs=model_DBOW.epochs)\n",
        "\n",
        "    # Generate training data\n",
        "    print(\"Generating training data...\")\n",
        "    X_train = [(list(model_DM.dv[i]) + list(model_DBOW.dv[i])) for i in range(len(train_corpus))]\n",
        "    Y_train = [doc[1] for doc in train_data]\n",
        "\n",
        "    # Oversample minority classes in training data\n",
        "    print(\"Balancing training data...\")\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_train_balanced, Y_train_balanced = ros.fit_resample(X_train, Y_train)\n",
        "\n",
        "    print(\"Generating testing data...\")\n",
        "    X_test = [(list(model_DM.infer_vector(test_corpus[i])) + list(model_DBOW.infer_vector(test_corpus[i]))) for i in range(len(test_corpus))]\n",
        "    Y_test = [doc[1] for doc in test_data]\n",
        "\n",
        "    return X_train_balanced, Y_train_balanced, X_test, Y_test\n",
        "\n",
        "def _read_corpus(data, tokens_only=False):\n",
        "    '''Helper function to prepare data for Doc2Vec.'''\n",
        "    for i, line in enumerate(data):\n",
        "        description = str(line[0]).strip()  # Ensure the description is a string and trimmed\n",
        "        if not description:\n",
        "            continue\n",
        "        tokens = gensim.utils.simple_preprocess(description)\n",
        "        if tokens_only:\n",
        "            yield tokens\n",
        "        else:\n",
        "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "# Classifier\n",
        "class ASP():\n",
        "    def __init__(self, X_train, Y_train, X_test, Y_test):\n",
        "        self.X_train, self.Y_train = X_train, Y_train\n",
        "        self.X_test, self.Y_test = X_test, Y_test\n",
        "        self.classifier = MLPClassifier(alpha=0.7, max_iter=10000)\n",
        "\n",
        "    def fit(self):\n",
        "        self.classifier.fit(self.X_train, self.Y_train)\n",
        "\n",
        "    def predict(self):\n",
        "        prediction = self.classifier.predict(self.X_test)\n",
        "        accuracy = accuracy_score(self.Y_test, prediction)\n",
        "        prf1 = precision_recall_fscore_support(y_true=self.Y_test, y_pred=prediction, average='weighted')\n",
        "\n",
        "        print('Evaluation Metrics:')\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print('Precision | Recall | F-Score')\n",
        "        pprint(prf1)\n",
        "\n",
        "# Dataset class\n",
        "class Dataset():\n",
        "    def __init__(self, path, project_id):\n",
        "        self.path = path\n",
        "        self.project_id = project_id\n",
        "\n",
        "# Experiment class\n",
        "class Experiment():\n",
        "    def __init__(self, train_data, test_data):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def run(self):\n",
        "        X_train, Y_train, X_test, Y_test = preprocess(self.train_data, self.test_data)\n",
        "        classifier = ASP(X_train, Y_train, X_test, Y_test)\n",
        "        classifier.fit()\n",
        "        classifier.predict()\n",
        "\n",
        "# Script to run experiment with CORE as test set\n",
        "a = Dataset('/content/mozilla_bug_report_data.csv', project_id=1)  # Replace with your dataset path\n",
        "train_data = load_data(a, train=True)\n",
        "test_data = load_data(a, train=False)\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "start = time.time()\n",
        "\n",
        "experiment = Experiment(train_data, test_data)\n",
        "experiment.run()\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "print('TOTAL RUNTIME: ', time.time() - start, 's')\n",
        "print('')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-uB3Wz1JKEF",
        "outputId": "b781cdd0-62b3-41c0-935b-8cdd61f86910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 27 19:01:35 2025\n",
            "Preprocessing training data...\n",
            "Number of valid training documents: 6893\n",
            "Preprocessing test data...\n",
            "Number of valid test documents: 2889\n",
            "Building vocabulary...\n",
            "Vocabulary size (DM): 24295\n",
            "Vocabulary size (DBOW): 24294\n",
            "Training models...\n",
            "Generating training data...\n",
            "Balancing training data...\n",
            "Generating testing data...\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.6383\n",
            "Precision | Recall | F-Score\n",
            "(0.7320354587508161, 0.6382831429560402, 0.6807283470053496, None)\n",
            "Mon Jan 27 19:07:20 2025\n",
            "TOTAL RUNTIME:  344.5559241771698 s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FireFox"
      ],
      "metadata": {
        "id": "xRXYnLbVEXEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for overlap between training and test data\n",
        "train_descriptions = set(train_data[:, 0])  # Set of unique descriptions in training data\n",
        "test_descriptions = set(test_data[:, 0])    # Set of unique descriptions in test data\n",
        "\n",
        "# Find overlap\n",
        "overlap = train_descriptions.intersection(test_descriptions)\n",
        "print(f\"Number of overlapping descriptions: {len(overlap)}\")\n",
        "if len(overlap) > 0:\n",
        "    print(\"Overlapping Descriptions:\", overlap)\n",
        "else:\n",
        "    print(\"No overlap between training and test data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddzdbIAEGXtv",
        "outputId": "3e0ef63b-38e5-4d59-805e-60ec4f868010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of overlapping descriptions: 0\n",
            "No overlap between training and test data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set Severity distribution:\")\n",
        "print(pd.Series([doc[1] for doc in train_data]).value_counts())\n",
        "print(\"Test set Severity distribution:\")\n",
        "print(pd.Series([doc[1] for doc in test_data]).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjcLYW3VGabt",
        "outputId": "4e5ad942-e044-4ad1-e199-09860364d44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set Severity distribution:\n",
            "2    7514\n",
            "4     690\n",
            "5     583\n",
            "1     259\n",
            "6     194\n",
            "Name: count, dtype: int64\n",
            "Test set Severity distribution:\n",
            "2    439\n",
            "4     45\n",
            "1     32\n",
            "5     18\n",
            "6      8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pprint import pprint\n",
        "import gensim\n",
        "import multiprocessing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Helper functions for data loading and preprocessing\n",
        "def load_data(dataset, train=True):\n",
        "    '''Reads in and formats data from the dataset based on product_name split.'''\n",
        "    df = pd.read_csv(dataset.path, sep=',', encoding='ISO-8859-1')\n",
        "    df = df.dropna(subset=[\"Severity\", \"Description\", \"product_name\"])  # Drop rows with missing columns\n",
        "    df['Severity'] = df['Severity'].astype(int)  # Convert Severity to int\n",
        "    df['Description'] = df['Description'].astype(str).str.strip()  # Ensure Description is a string\n",
        "\n",
        "    # Filter out invalid rows\n",
        "    df = df[df['Description'] != '']\n",
        "\n",
        "    # Split based on product_name\n",
        "    test_data = df[df['product_name'] == 'FIREFOX'][['Description', 'Severity']].to_numpy()\n",
        "    train_data = df[df['product_name'] != 'FIREFOX'][['Description', 'Severity']].to_numpy()\n",
        "\n",
        "    return train_data if train else test_data\n",
        "\n",
        "def preprocess(train_data, test_data):\n",
        "    '''Generate paragraph vectors using Doc2Vec.'''\n",
        "    print(\"Preprocessing training data...\")\n",
        "    train_corpus = list(_read_corpus(train_data))\n",
        "    print(f\"Number of valid training documents: {len(train_corpus)}\")\n",
        "\n",
        "    print(\"Preprocessing test data...\")\n",
        "    test_corpus = list(_read_corpus(test_data, tokens_only=True))\n",
        "    print(f\"Number of valid test documents: {len(test_corpus)}\")\n",
        "\n",
        "    if len(train_corpus) == 0 or len(test_corpus) == 0:\n",
        "        raise ValueError(\"No valid data found after preprocessing. Check the input data.\")\n",
        "\n",
        "    cores = max(1, multiprocessing.cpu_count() // 2)  # Use half the cores\n",
        "\n",
        "    # Initialize Doc2Vec models\n",
        "    model_DM = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=1, dm_concat=1)\n",
        "    model_DBOW = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=1, epochs=100, workers=cores, dm=0)\n",
        "\n",
        "    # Build vocabulary\n",
        "    print(\"Building vocabulary...\")\n",
        "    model_DM.build_vocab(train_corpus)\n",
        "    model_DBOW.build_vocab(train_corpus)\n",
        "\n",
        "    print(f\"Vocabulary size (DM): {len(model_DM.wv.key_to_index)}\")\n",
        "    print(f\"Vocabulary size (DBOW): {len(model_DBOW.wv.key_to_index)}\")\n",
        "\n",
        "    if len(model_DM.wv.key_to_index) == 0 or len(model_DBOW.wv.key_to_index) == 0:\n",
        "        raise ValueError(\"Vocabulary is empty. Check your input data or preprocessing.\")\n",
        "\n",
        "    # Train Doc2Vec models\n",
        "    print(\"Training models...\")\n",
        "    model_DM.train(train_corpus, total_examples=model_DM.corpus_count, epochs=model_DM.epochs)\n",
        "    model_DBOW.train(train_corpus, total_examples=model_DBOW.corpus_count, epochs=model_DBOW.epochs)\n",
        "\n",
        "    # Generate training data\n",
        "    print(\"Generating training data...\")\n",
        "    X_train = [(list(model_DM.dv[i]) + list(model_DBOW.dv[i])) for i in range(len(train_corpus))]\n",
        "    Y_train = [doc[1] for doc in train_data]\n",
        "\n",
        "    # Oversample minority classes in training data\n",
        "    print(\"Balancing training data...\")\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_train_balanced, Y_train_balanced = ros.fit_resample(X_train, Y_train)\n",
        "\n",
        "    print(\"Generating testing data...\")\n",
        "    X_test = [(list(model_DM.infer_vector(test_corpus[i])) + list(model_DBOW.infer_vector(test_corpus[i]))) for i in range(len(test_corpus))]\n",
        "    Y_test = [doc[1] for doc in test_data]\n",
        "\n",
        "    return X_train_balanced, Y_train_balanced, X_test, Y_test\n",
        "\n",
        "def _read_corpus(data, tokens_only=False):\n",
        "    '''Helper function to prepare data for Doc2Vec.'''\n",
        "    for i, line in enumerate(data):\n",
        "        description = str(line[0]).strip()  # Ensure the description is a string and trimmed\n",
        "        if not description:\n",
        "            continue\n",
        "        tokens = gensim.utils.simple_preprocess(description)\n",
        "        if tokens_only:\n",
        "            yield tokens\n",
        "        else:\n",
        "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "# Classifier\n",
        "class ASP():\n",
        "    def __init__(self, X_train, Y_train, X_test, Y_test):\n",
        "        self.X_train, self.Y_train = X_train, Y_train\n",
        "        self.X_test, self.Y_test = X_test, Y_test\n",
        "        self.classifier = MLPClassifier(alpha=0.7, max_iter=10000)\n",
        "\n",
        "    def fit(self):\n",
        "        self.classifier.fit(self.X_train, self.Y_train)\n",
        "\n",
        "    def predict(self):\n",
        "        prediction = self.classifier.predict(self.X_test)\n",
        "        accuracy = accuracy_score(self.Y_test, prediction)\n",
        "        prf1 = precision_recall_fscore_support(y_true=self.Y_test, y_pred=prediction, average='weighted')\n",
        "\n",
        "        print('Evaluation Metrics:')\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print('Precision | Recall | F-Score')\n",
        "        pprint(prf1)\n",
        "\n",
        "# Dataset class\n",
        "class Dataset():\n",
        "    def __init__(self, path, project_id):\n",
        "        self.path = path\n",
        "        self.project_id = project_id\n",
        "\n",
        "# Experiment class\n",
        "class Experiment():\n",
        "    def __init__(self, train_data, test_data):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def run(self):\n",
        "        X_train, Y_train, X_test, Y_test = preprocess(self.train_data, self.test_data)\n",
        "        classifier = ASP(X_train, Y_train, X_test, Y_test)\n",
        "        classifier.fit()\n",
        "        classifier.predict()\n",
        "\n",
        "# Script to run experiment with CORE as test set\n",
        "a = Dataset('/content/mozilla_bug_report_data.csv', project_id=1)  # Replace with your dataset path\n",
        "train_data = load_data(a, train=True)\n",
        "test_data = load_data(a, train=False)\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "start = time.time()\n",
        "\n",
        "experiment = Experiment(train_data, test_data)\n",
        "experiment.run()\n",
        "\n",
        "print(time.ctime(time.time()))\n",
        "print('TOTAL RUNTIME: ', time.time() - start, 's')\n",
        "print('')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kxF9mJGHYlV",
        "outputId": "aba38297-123c-484a-a4e3-abe9580b6f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 27 18:54:02 2025\n",
            "Preprocessing training data...\n",
            "Number of valid training documents: 9240\n",
            "Preprocessing test data...\n",
            "Number of valid test documents: 542\n",
            "Building vocabulary...\n",
            "Vocabulary size (DM): 30768\n",
            "Vocabulary size (DBOW): 30767\n",
            "Training models...\n",
            "Generating training data...\n",
            "Balancing training data...\n",
            "Generating testing data...\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.6716\n",
            "Precision | Recall | F-Score\n",
            "(0.7316051156879086, 0.6715867158671587, 0.6973252146490013, None)\n",
            "Mon Jan 27 18:58:36 2025\n",
            "TOTAL RUNTIME:  273.7646908760071 s\n",
            "\n"
          ]
        }
      ]
    }
  ]
}